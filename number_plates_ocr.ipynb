{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrAwdpNiuqq1Th+vYRzBcI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgorZorkov/number-plates-ocr/blob/main/number_plates_ocr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-V-OzBGwrsAO"
      },
      "outputs": [],
      "source": [
        "!pip install onnxruntime\n",
        "!pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "id": "f7IajGJ9v9X3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://github.com/IgorZorkov/number-plates-ocr/releases/download/1.0/number_plates_ocr.zip\""
      ],
      "metadata": {
        "id": "7E8wOP6uuiW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/number_plates_ocr.zip', 'r') as zipObj:\n",
        "   zipObj.extractall('/content')"
      ],
      "metadata": {
        "id": "8FAeBK1Dv2He"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import onnxruntime\n",
        "import json\n",
        "import os\n",
        "import statistics\n",
        "from scipy.special import softmax\n",
        "import time\n",
        "\n",
        "def read_vocab(path):\n",
        "    with open(path) as f:\n",
        "        vocab = json.load(f)\n",
        "    return vocab\n",
        "\n",
        "def norm(x):\n",
        "    mean = [0.5, 0.5, 0.5]\n",
        "    std = [0.5, 0.5, 0.5]\n",
        "    x = x / 255.0\n",
        "    x[0, :, :] -= mean[0]\n",
        "    x[1, :, :] -= mean[1]\n",
        "    x[2, :, :] -= mean[2]\n",
        "    x[0, :, :] /= std[0]\n",
        "    x[1, :, :] /= std[1]\n",
        "    x[2, :, :] /= std[2]\n",
        "    return x\n",
        "\n",
        "def decode_text(tokens, vocab, vocab_inp):\n",
        "    start = vocab.get('<s>')\n",
        "    end = vocab.get('</s>')\n",
        "    unk = vocab.get('<unk>')\n",
        "    pad = vocab.get('<pad>')\n",
        "    text = ''\n",
        "    for i in tokens:\n",
        "        if i == end:\n",
        "            break\n",
        "        if i not in [end, start, pad, unk]:\n",
        "            text += vocab_inp[i]\n",
        "    return text\n",
        "\n",
        "class OnnxEncoder(object):\n",
        "    def __init__(self, model_path):\n",
        "        self.model = onnxruntime.InferenceSession(model_path, providers=onnxruntime.get_available_providers())\n",
        "\n",
        "    def __call__(self, image):\n",
        "        onnx_inputs = {self.model.get_inputs()[0].name: np.asarray(image, dtype='float32')}\n",
        "        onnx_output = self.model.run(None, onnx_inputs)[0]\n",
        "\n",
        "        return onnx_output\n",
        "\n",
        "class OnnxDecoder(object):\n",
        "    def __init__(self, model_path):\n",
        "        self.model = onnxruntime.InferenceSession(model_path, providers=onnxruntime.get_available_providers())\n",
        "        self.input_names = {input_key.name: idx for idx, input_key in enumerate(self.model.get_inputs())}\n",
        "\n",
        "    def __call__(self, input_ids,\n",
        "                 encoder_hidden_states):\n",
        "        onnx_inputs = {\"input_ids\": input_ids, \"encoder_hidden_states\": encoder_hidden_states}\n",
        "        onnx_output = self.model.run(['logits'], onnx_inputs)\n",
        "        return onnx_output\n",
        "\n",
        "def inference(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = image[..., ::-1]\n",
        "    image = cv2.resize(image, (384, 384), 1)\n",
        "\n",
        "    pixel_values = cv2.split(np.array(image))\n",
        "    pixel_values = norm(np.array(pixel_values))\n",
        "    pixel_values = np.array([pixel_values])\n",
        "    encoder_output = encoder(pixel_values)\n",
        "    ids = [vocab[\"<s>\"], ]\n",
        "    mask = [1, ]\n",
        "    scores = []\n",
        "    for i in range(max_len):\n",
        "        input_ids = np.array([ids])\n",
        "        attention_mask = np.array([mask])\n",
        "        decoder_output = decoder(input_ids=input_ids, encoder_hidden_states=encoder_output)\n",
        "        pred = decoder_output[0][0]\n",
        "        pred = softmax(pred, axis=1)\n",
        "        max_index = pred.argmax(axis=1)\n",
        "        if max_index[-1] == vocab[\"</s>\"]:\n",
        "            break\n",
        "        scores.append(pred[max_index.shape[0] - 1, max_index[-1]])\n",
        "        ids.append(max_index[-1])\n",
        "        mask.append(1)\n",
        "    #print(\"score：{}\".format(scores))\n",
        "    print(\"score：{}\".format(statistics.mean(scores)))\n",
        "    if threshold < statistics.mean(scores):\n",
        "      text = decode_text(ids, vocab, vocab_inp)\n",
        "    else:\n",
        "      text = \"\"\n",
        "    return text"
      ],
      "metadata": {
        "id": "otYbzoWZr8Gd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content\"\n",
        "encoder = OnnxEncoder(os.path.join(model_path, \"encoder.onnx\"))\n",
        "decoder = OnnxDecoder(os.path.join(model_path, \"decoder.onnx\"))\n",
        "vocab = read_vocab(os.path.join(model_path, \"vocab.json\"))\n",
        "vocab_inp = {vocab[key]: key for key in vocab}\n",
        "threshold = 0.5\n",
        "max_len = 64"
      ],
      "metadata": {
        "id": "A3m5BkvDr8Us"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = inference(\"/content/0001.jpg\")\n",
        "print(\"text: \", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nbxx3ymBoaxs",
        "outputId": "537ce4fa-ee22-4dd8-8c2e-e4142c5d1516"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score：0.9992455840110779\n",
            "text:  С569НН35\n"
          ]
        }
      ]
    }
  ]
}