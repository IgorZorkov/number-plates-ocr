{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZcfFZPyXeKpbrxsrkhOxm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgorZorkov/number-plates-ocr/blob/main/number_plates_ocr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-V-OzBGwrsAO"
      },
      "outputs": [],
      "source": [
        "!pip install onnxruntime\n",
        "!pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "id": "f7IajGJ9v9X3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "url = f\"https://drive.google.com/open?id=1MmrEB8f91ZmS6k_vbQ8C5VIXPthVd4WY\"\n",
        "#https://drive.google.com/open?id=1MmrEB8f91ZmS6k_vbQ8C5VIXPthVd4WY\n",
        "output = 'number_plates_ocr.zip'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "id": "7E8wOP6uuiW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/number_plates_ocr.zip', 'r') as zipObj:\n",
        "   zipObj.extractall('/content')"
      ],
      "metadata": {
        "id": "8FAeBK1Dv2He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import onnxruntime\n",
        "import json\n",
        "import os\n",
        "import statistics\n",
        "from scipy.special import softmax\n",
        "import time\n",
        "\n",
        "def read_vocab(path):\n",
        "    with open(path) as f:\n",
        "        vocab = json.load(f)\n",
        "    return vocab\n",
        "\n",
        "def norm(x):\n",
        "    mean = [0.5, 0.5, 0.5]\n",
        "    std = [0.5, 0.5, 0.5]\n",
        "    x = x / 255.0\n",
        "    x[0, :, :] -= mean[0]\n",
        "    x[1, :, :] -= mean[1]\n",
        "    x[2, :, :] -= mean[2]\n",
        "    x[0, :, :] /= std[0]\n",
        "    x[1, :, :] /= std[1]\n",
        "    x[2, :, :] /= std[2]\n",
        "    return x\n",
        "\n",
        "def decode_text(tokens, vocab, vocab_inp):\n",
        "    start = vocab.get('<s>')\n",
        "    end = vocab.get('</s>')\n",
        "    unk = vocab.get('<unk>')\n",
        "    pad = vocab.get('<pad>')\n",
        "    text = ''\n",
        "    for i in tokens:\n",
        "        if i == end:\n",
        "            break\n",
        "        if i not in [end, start, pad, unk]:\n",
        "            text += vocab_inp[i]\n",
        "    return text\n",
        "\n",
        "class OnnxEncoder(object):\n",
        "    def __init__(self, model_path):\n",
        "        self.model = onnxruntime.InferenceSession(model_path, providers=onnxruntime.get_available_providers())\n",
        "\n",
        "    def __call__(self, image):\n",
        "        onnx_inputs = {self.model.get_inputs()[0].name: np.asarray(image, dtype='float32')}\n",
        "        onnx_output = self.model.run(None, onnx_inputs)[0]\n",
        "\n",
        "        return onnx_output\n",
        "\n",
        "class OnnxDecoder(object):\n",
        "    def __init__(self, model_path):\n",
        "        self.model = onnxruntime.InferenceSession(model_path, providers=onnxruntime.get_available_providers())\n",
        "        self.input_names = {input_key.name: idx for idx, input_key in enumerate(self.model.get_inputs())}\n",
        "\n",
        "    def __call__(self, input_ids,\n",
        "                 encoder_hidden_states):\n",
        "        onnx_inputs = {\"input_ids\": input_ids, \"encoder_hidden_states\": encoder_hidden_states}\n",
        "        onnx_output = self.model.run(['logits'], onnx_inputs)\n",
        "        return onnx_output\n",
        "\n",
        "class OnnxEncoderDecoder(object):\n",
        "    def __init__(self, model_path):\n",
        "        self.encoder = OnnxEncoder(os.path.join(model_path, \"encoder_model.onnx\"))\n",
        "        self.decoder = OnnxDecoder(os.path.join(model_path, \"decoder_model.onnx\"))\n",
        "        self.vocab = read_vocab(os.path.join(model_path, \"vocab.json\"))\n",
        "        self.vocab_inp = {self.vocab[key]: key for key in self.vocab}\n",
        "        self.threshold = 0.5\n",
        "        self.max_len = 64\n",
        "\n",
        "    def run(self, image):\n",
        "        image = cv2.resize(image, (384, 384), 1)\n",
        "\n",
        "        pixel_values = cv2.split(np.array(image))\n",
        "        pixel_values = norm(np.array(pixel_values))\n",
        "        pixel_values = np.array([pixel_values])\n",
        "        encoder_output = self.encoder(pixel_values)\n",
        "        ids = [self.vocab[\"<s>\"], ]\n",
        "        mask = [1, ]\n",
        "        scores = []\n",
        "        for i in range(self.max_len):\n",
        "            input_ids = np.array([ids])\n",
        "            attention_mask = np.array([mask])\n",
        "            decoder_output = self.decoder(input_ids=input_ids, encoder_hidden_states=encoder_output)\n",
        "            pred = decoder_output[0][0]\n",
        "            pred = softmax(pred, axis=1)\n",
        "            max_index = pred.argmax(axis=1)\n",
        "            if max_index[-1] == self.vocab[\"</s>\"]:\n",
        "                break\n",
        "            scores.append(pred[max_index.shape[0] - 1, max_index[-1]])\n",
        "            ids.append(max_index[-1])\n",
        "            mask.append(1)\n",
        "        print(\"scoreï¼š{}\".format(statistics.mean(scores)))\n",
        "        if self.threshold < statistics.mean(scores):\n",
        "          text = decode_text(ids, self.vocab, self.vocab_inp)\n",
        "        else:\n",
        "          text = \"\"\n",
        "        return text\n",
        "\n",
        "model = OnnxEncoderDecoder(\"/content\")"
      ],
      "metadata": {
        "id": "otYbzoWZr8Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(\"/content/test.jpg\")\n",
        "image = image[..., ::-1]\n",
        "result = model.run(image)\n",
        "print(\"text: \", result)"
      ],
      "metadata": {
        "id": "A3m5BkvDr8Us"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}